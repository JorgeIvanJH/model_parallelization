{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19e7e545",
   "metadata": {},
   "source": [
    "note: exercises only to validate inference time, and for inference time improvement using parallelization techniques. So many wrong practices for training, and testing will be done (e.g. purposely diplicating rows to virtually increase the dataset, and testing on the same training set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ab055fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "repo_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "sys.path.append(repo_root)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "import datetime\n",
    "\n",
    "\n",
    "\n",
    "NUM_ROWS = int(1e7) # Number of rows to read from the dataset\n",
    "N_JOBS_MODEL = os.cpu_count() # Number of jobs supported within the model itself\n",
    "ROOT_DIR = os.path.abspath(os.path.join(os.getcwd(), \"..\",\"..\",\"..\"))\n",
    "DATASET_PATH = os.path.join(ROOT_DIR, \"data\", \"healthcare_noshows_appointments.csv\")\n",
    "MODELSAVE_PATH = os.path.join(ROOT_DIR, \"src\", \"ml\", \"saved_models\")\n",
    "\n",
    "def pipeline(X,model):\n",
    "\n",
    "    categorical_features = [col for col in X.columns if X[col].dtype == 'category']\n",
    "    numeric_features = [col for col in X.columns if X[col].dtype in ['int64', 'float64', 'bool']]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), ['Gender', 'Neighbourhood']),\n",
    "            ('num', StandardScaler(), numeric_features)\n",
    "        ]\n",
    "    )\n",
    "    modelwpipeline = Pipeline([\n",
    "        ('preprocess', preprocessor),\n",
    "        ('logreg', model)\n",
    "    ])\n",
    "    return modelwpipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d8e53d",
   "metadata": {},
   "source": [
    "#### basic data processing\n",
    "\n",
    "dataset over or undersampled for speed testing only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b41c5cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 0 to 9999999\n",
      "Data columns (total 13 columns):\n",
      " #   Column          Dtype         \n",
      "---  ------          -----         \n",
      " 0   Gender          category      \n",
      " 1   ScheduledDay    datetime64[ns]\n",
      " 2   AppointmentDay  datetime64[ns]\n",
      " 3   Age             int64         \n",
      " 4   Neighbourhood   category      \n",
      " 5   Scholarship     bool          \n",
      " 6   Hipertension    bool          \n",
      " 7   Diabetes        bool          \n",
      " 8   Alcoholism      bool          \n",
      " 9   Handcap         bool          \n",
      " 10  SMS_received    bool          \n",
      " 11  Showed_up       bool          \n",
      " 12  Date.diff       int64         \n",
      "dtypes: bool(7), category(2), datetime64[ns](2), int64(2)\n",
      "memory usage: 391.0 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>ScheduledDay</th>\n",
       "      <th>AppointmentDay</th>\n",
       "      <th>Age</th>\n",
       "      <th>Neighbourhood</th>\n",
       "      <th>Scholarship</th>\n",
       "      <th>Hipertension</th>\n",
       "      <th>Diabetes</th>\n",
       "      <th>Alcoholism</th>\n",
       "      <th>Handcap</th>\n",
       "      <th>SMS_received</th>\n",
       "      <th>Showed_up</th>\n",
       "      <th>Date.diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>62</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>56</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>62</td>\n",
       "      <td>MATA DA PRAIA</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>8</td>\n",
       "      <td>PONTAL DE CAMBURI</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>F</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>2016-04-29</td>\n",
       "      <td>56</td>\n",
       "      <td>JARDIM DA PENHA</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender ScheduledDay AppointmentDay  Age      Neighbourhood  Scholarship  \\\n",
       "0      F   2016-04-29     2016-04-29   62    JARDIM DA PENHA        False   \n",
       "1      M   2016-04-29     2016-04-29   56    JARDIM DA PENHA        False   \n",
       "2      F   2016-04-29     2016-04-29   62      MATA DA PRAIA        False   \n",
       "3      F   2016-04-29     2016-04-29    8  PONTAL DE CAMBURI        False   \n",
       "4      F   2016-04-29     2016-04-29   56    JARDIM DA PENHA        False   \n",
       "\n",
       "   Hipertension  Diabetes  Alcoholism  Handcap  SMS_received  Showed_up  \\\n",
       "0          True     False       False    False         False       True   \n",
       "1         False     False       False    False         False       True   \n",
       "2         False     False       False    False         False       True   \n",
       "3         False     False       False    False         False       True   \n",
       "4          True      True       False    False         False       True   \n",
       "\n",
       "   Date.diff  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(DATASET_PATH, dtype={'PatientId': 'category',\n",
    "                                      'AppointmentID': 'category',\n",
    "                                      'Gender': 'category',\n",
    "                                      'Neighbourhood': 'category',\n",
    "                                      }, \n",
    "                                parse_dates=['ScheduledDay', \n",
    "                                             'AppointmentDay'])\n",
    "df = df.drop(columns=['AppointmentID', 'PatientId'])\n",
    "n_rows = df.shape[0]\n",
    "nrepeats,remiainder = NUM_ROWS // n_rows , NUM_ROWS % n_rows\n",
    "df = pd.concat([df]*nrepeats + [df.sample(remiainder)], ignore_index=True)\n",
    "display(df.info())\n",
    "display(df.head())\n",
    "y = df[\"Showed_up\"]\n",
    "X = df.drop(columns=[\"Showed_up\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f5b6de",
   "metadata": {},
   "source": [
    "# SKLearn Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27179ed9",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "93a79cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 5.957391023635864 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['c:\\\\Users\\\\jjaramil\\\\OneDrive - InterSystems Corporation\\\\Documents\\\\model_parallelization\\\\models\\\\LogisticRegression_1150_28112025.joblib']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MODEL DEFINITION\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(max_iter=1000,solver='lbfgs', class_weight=\"balanced\", n_jobs=N_JOBS_MODEL)\n",
    "modelp = pipeline(X,model)\n",
    "\n",
    "# TRAINING\n",
    "start_time = time.time()\n",
    "modelp.fit(X, y)\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time} seconds\")\n",
    "\n",
    "# SAVING\n",
    "datetime_now = datetime.datetime.now().strftime(\"%H%M_%d%m%Y\")\n",
    "model_name = model.__class__.__name__ + f\"_{datetime_now}.joblib\"\n",
    "model_save_path = os.path.join(MODELSAVE_PATH, model_name)\n",
    "joblib.dump(modelp, model_save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58939ca",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe8a710",
   "metadata": {},
   "source": [
    "## Additional data preparation for LighGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93c2ca2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000000 entries, 0 to 9999999\n",
      "Data columns (total 22 columns):\n",
      " #   Column                      Dtype\n",
      "---  ------                      -----\n",
      " 0   Age                         int64\n",
      " 1   Scholarship                 bool \n",
      " 2   Hipertension                bool \n",
      " 3   Diabetes                    bool \n",
      " 4   Alcoholism                  bool \n",
      " 5   Handcap                     bool \n",
      " 6   SMS_received                bool \n",
      " 7   Date.diff                   int64\n",
      " 8   ScheduledDay_year           int32\n",
      " 9   ScheduledDay_month          int32\n",
      " 10  ScheduledDay_day            int32\n",
      " 11  ScheduledDay_dow            int32\n",
      " 12  ScheduledDay_hour           int32\n",
      " 13  ScheduledDay_is_weekend     int8 \n",
      " 14  ScheduledDay_part_of_day    int8 \n",
      " 15  AppointmentDay_year         int32\n",
      " 16  AppointmentDay_month        int32\n",
      " 17  AppointmentDay_day          int32\n",
      " 18  AppointmentDay_dow          int32\n",
      " 19  AppointmentDay_hour         int32\n",
      " 20  AppointmentDay_is_weekend   int8 \n",
      " 21  AppointmentDay_part_of_day  int8 \n",
      "dtypes: bool(6), int32(10), int64(2), int8(4)\n",
      "memory usage: 629.4 MB\n"
     ]
    }
   ],
   "source": [
    "# DATA PREPARATION (slight difference for LightGBM)\n",
    "date_cols = [\"ScheduledDay\", \"AppointmentDay\"]\n",
    "\n",
    "# 1. Extract useful components\n",
    "for col in date_cols:\n",
    "    X[col + \"_year\"] = X[col].dt.year\n",
    "    X[col + \"_month\"] = X[col].dt.month\n",
    "    X[col + \"_day\"] = X[col].dt.day\n",
    "    X[col + \"_dow\"] = X[col].dt.dayofweek         # 0=Mon, 6=Sun\n",
    "    X[col + \"_hour\"] = X[col].dt.hour\n",
    "    X[col + \"_is_weekend\"] = (X[col].dt.dayofweek >= 5).astype(\"int8\")\n",
    "    \n",
    "    # Optional: Part-of-day feature\n",
    "    X[col + \"_part_of_day\"] = pd.cut(\n",
    "        X[col].dt.hour,\n",
    "        bins=[-1, 6, 12, 17, 24],\n",
    "        labels=[0, 1, 2, 3],        # 0=night,1=morning,2=afternoon,3=evening\n",
    "        ordered=True\n",
    "    ).astype(\"int8\")\n",
    "X = X.drop(columns=date_cols)\n",
    "\n",
    "# DROP CATEGORICAL FEATURES (just for now)\n",
    "X = X.drop(columns=[\"Gender\", \"Neighbourhood\"])\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd4ea88",
   "metadata": {},
   "source": [
    "## Training and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "92fd74d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7973594, number of negative: 2026406\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.239529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 105\n",
      "[LightGBM] [Info] Number of data points in the train set: 10000000, number of used features: 18\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.797359 -> initscore=1.369872\n",
      "[LightGBM] [Info] Start training from score 1.369872\n",
      "Training time: 4.935598611831665 seconds\n",
      "Inference time: 0.9510607719421387 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x23a7091b1d0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import gc\n",
    "\n",
    "\n",
    "# MODEL DEFINITION\n",
    "train_data = lgb.Dataset(X, label=y, free_raw_data=True)\n",
    "validation_data = lgb.Dataset(X, label=y, reference=train_data)\n",
    "train_data.raw_data = None\n",
    "gc.collect()\n",
    "base_params = {\n",
    "    'objective': 'binary',\n",
    "    'metric': 'binary_logloss',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'n_jobs': N_JOBS_MODEL,\n",
    "    \n",
    "}\n",
    "\n",
    "gpu_params = base_params | {\n",
    "    \"device_type\": \"cpu\",\n",
    "    # 'gpu_platform_id': 0,\n",
    "    # 'gpu_device_id': 0,\n",
    "    \"max_bin\": 15,\n",
    "    \"gpu_use_dp\": False\n",
    "}\n",
    "\n",
    "# TRAINING\n",
    "num_round = 10\n",
    "start_time = time.time()\n",
    "bst = lgb.train(gpu_params, train_data, num_round, valid_sets=[validation_data])\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {end_time - start_time} seconds\")\n",
    "\n",
    "# TEST INFERENCE TIME\n",
    "start_time = time.time()\n",
    "y_pred = bst.predict(X)\n",
    "end_time = time.time()\n",
    "print(f\"Inference time: {end_time - start_time} seconds\")\n",
    "\n",
    "# SAVING\n",
    "datetime_now = datetime.datetime.now().strftime(\"%H%M_%d%m%Y\")\n",
    "model_name = \"LightGBM_\" + f\"{datetime_now}.txt\"\n",
    "model_save_path = os.path.join(MODELSAVE_PATH, model_name)\n",
    "bst.save_model(model_save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4362ec80",
   "metadata": {},
   "source": [
    "## ONNX Acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "712b6791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\jjaramil\\\\OneDrive - InterSystems Corporation\\\\Documents\\\\model_parallelization\\\\src\\\\ml\\\\saved_models\\\\LightGBM_1207_04122025.txt'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_save_path # Change if need to load a different model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "778e398b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import onnxmltools\n",
    "from onnxmltools.convert.common.data_types import FloatTensorType\n",
    "\n",
    "# CONVERSION TO ONNX\n",
    "initial_type = [('input', FloatTensorType([None, X.shape[1]]))]\n",
    "onnx_model = onnxmltools.convert_lightgbm(bst, initial_types=initial_type)\n",
    "\n",
    "# SAVING ONNX MODEL\n",
    "onnx_model_name = \"LightGBM_\" + f\"{datetime_now}.onnx\"\n",
    "onnx_model_save_path = os.path.join(MODELSAVE_PATH, onnx_model_name)    \n",
    "onnxmltools.utils.save_model(onnx_model, onnx_model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6eddf5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jjaramil\\AppData\\Local\\anaconda3\\envs\\python313\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:123: UserWarning: Specified provider 'CUDAExecutionProvider' is not in available provider names.Available providers: 'AzureExecutionProvider, CPUExecutionProvider'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Providers: ['CPUExecutionProvider']\n",
      "Using: {'CPUExecutionProvider': {}}\n",
      "Input name: input\n",
      "ONNX Inference time: 9.925181865692139 seconds\n"
     ]
    }
   ],
   "source": [
    "# INFERENCE TEST\n",
    "import onnxruntime as ort\n",
    "\n",
    "# Load onnx model with providers\n",
    "session = ort.InferenceSession(\n",
    "    onnx_model_save_path,\n",
    "    providers=[\"CUDAExecutionProvider\", \"CPUExecutionProvider\"]\n",
    ")\n",
    "\n",
    "# Check which provider is actually used\n",
    "print(\"Providers:\", session.get_providers())\n",
    "print(\"Using:\", session.get_provider_options())\n",
    "X_test_onnx = X.to_numpy(dtype=np.float32)   # or: X.values.astype(np.float32)\n",
    "\n",
    "input_name = session.get_inputs()[0].name\n",
    "print(\"Input name:\", input_name)\n",
    "\n",
    "start_time = time.time()\n",
    "preds = session.run(\n",
    "    None,  # means \"return all outputs\"\n",
    "    {input_name: X_test_onnx}\n",
    ")[0]\n",
    "end_time = time.time()\n",
    "print(f\"ONNX Inference time: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cf126d",
   "metadata": {},
   "source": [
    "# FIL Acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c6d6257c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cuml'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcuml\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ForestInference\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'cuml'"
     ]
    }
   ],
   "source": [
    "from cuml import ForestInference\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
